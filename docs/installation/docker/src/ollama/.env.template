# =================================================================
# Ollama Configuration
# This file contains environment variables for the Ollama service
# =================================================================

# Network Configuration
OLLAMA_PORT=11434
OLLAMA_HTTPS_PORT=11443

# SSL Configuration
# Set to 'true' to enable HTTPS via Nginx reverse proxy
OLLAMA_ENABLE_SSL=false
OLLAMA_DOMAIN=localhost

# GPU Configuration
# Options: nvidia, amd, none
OLLAMA_GPU_DRIVER=none
OLLAMA_GPU_LAYERS=999

# Performance Configuration
# Number of parallel requests to handle
OLLAMA_NUM_PARALLEL=4

# Maximum number of models to keep loaded in memory
OLLAMA_MAX_LOADED_MODELS=2

# How long to keep models loaded (e.g., 5m, 30m, 1h)
OLLAMA_KEEP_ALIVE=5m

# Debug Configuration
# Set to 1 to enable verbose logging
OLLAMA_DEBUG=0

# Timezone
TZ=UTC

# =================================================================
# DO NOT COMMIT THIS FILE TO VERSION CONTROL
# Add .env to your .gitignore file
# =================================================================
